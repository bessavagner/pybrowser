{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "To use `thatscraper` in a project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill simple form\n",
    "\n",
    "Usually, forms are tag elements, threrefore you can select the html form structure using \"tag name\". Howerver, in example below the form is in a div, with a class name \"form\". You should always inspect the page to check out the structure of the element you want to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import thatscraper\n",
    "\n",
    "crawler = thatscraper.Crawler()\n",
    "# open page\n",
    "crawler.goto(\"https://phptravels.com/demo/\")\n",
    "# get form wrapper\n",
    "form_element = crawler.element(\"form\", \"class name\")\n",
    "# form fields\n",
    "elements = crawler.children_of(form_element, \"input\", \"tag name\")\n",
    "# data to fill\n",
    "data = {\n",
    "    'first name': 'John',\n",
    "    'last name': 'Doe',\n",
    "    'bus name': 'Joe',\n",
    "    'email': 'j.doe@gmail.com'\n",
    "}\n",
    "# filling\n",
    "for element, field in zip(elements, data):\n",
    "    crawler.send_to_element(element, data[field])\n",
    "# wait long enough so you can check the result\n",
    "time.sleep(5)\n",
    "\n",
    "# always quit the driver\n",
    "crawler.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a table\n",
    "\n",
    "To scrap, collect ou handle data informations, such as text, tables or images, ```thatscraper``` comes with the module ```extractor``` to work with elements or addresses and return the desired data as needed. Here is an example of obtaining a table as ```pandas.DataFrame object```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Company           Contact  Country\n",
      "0          Google      Maria Anders  Germany\n",
      "1            Meta   Francisco Chang   Mexico\n",
      "2       Microsoft     Roland Mendel  Austria\n",
      "3  Island Trading     Helen Bennett       UK\n",
      "4           Adobe   Yoshi Tannamuri   Canada\n",
      "5          Amazon  Giovanni Rovelli    Italy\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import thatscraper as ts\n",
    "\n",
    "crawler = ts.Crawler(browser='chrome')\n",
    "\n",
    "crawler.goto(\"https://www.techlistic.com/p/demo-selenium-practice.html\")\n",
    "costumers_table = ts.extractor.Table(crawler, \"customers\", \"id\")\n",
    "\n",
    "# table as pandas dataframe (see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)\n",
    "print(costumers_table.data[0])\n",
    "\n",
    "# compare results\n",
    "time.sleep(10)\n",
    "crawler.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get items from lists\n",
    "\n",
    "As stated, the  `extractor` module is suitable to retrieve informations. Like in example above, where `Table` is responsible to get the element convert the html into a dataframe. Here is an example where we can obtain the list items in html format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li><a href=\"https://www.techlistic.com/2017/02/how-to-handle-dynamic-web-table-in.html\">Verify that there are only 4 structure values present in the table with Selenium</a></li>\n",
      "<li><a href=\"https://www.techlistic.com/2017/02/how-to-handle-dynamic-web-table-in.html\">Verify that 6th row of the table (Last Row) has only two columns with Selenium</a></li>\n",
      "<li><a href=\"https://www.techlistic.com/2017/02/how-to-handle-dynamic-web-table-in.html\">Find the tallest structure in the table with Selenium</a></li>\n"
     ]
    }
   ],
   "source": [
    "import thatscraper as ts\n",
    "\n",
    "crawler = ts.Crawler(browser='chrome', headless=True)\n",
    "\n",
    "crawler.goto(\"https://www.techlistic.com/p/demo-selenium-practice.html\")\n",
    "\n",
    "items = ts.extractor.UnorderedList(crawler, \"(//div[@dir=\\'ltr\\'])[7]\", \"xpath\")\n",
    "\n",
    "for item in items:\n",
    "    li = ts.extractor.html(item)\n",
    "    print(li)\n",
    "crawler.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download images\n",
    "\n",
    "When working with search in websites, always prefer to place the query in the url instead of sent to input element the intended query. This is to avoid reacaptcha or other bot indentifier methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"kitty-cat-kitten-pet-45201.jpeg\" style=\"display:inline;margin:1px;width:100px;\"/><img src=\"pexels-photo-320014.jpeg\" style=\"display:inline;margin:1px;width:100px;\"/><img src=\"cat-sweet-kitty-animals-57416.jpeg\" style=\"display:inline;margin:1px;width:100px;\"/><img src=\"pexels-photo.jpg\" style=\"display:inline;margin:1px;width:100px;\"/><img src=\"pexels-photo-1056251.jpeg\" style=\"display:inline;margin:1px;width:100px;\"/><img src=\"pexels-photo-774731.jpeg\" style=\"display:inline;margin:1px;width:100px;\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import thatscraper as ts\n",
    "\n",
    "crawler = ts.Crawler()\n",
    "\n",
    "# let's get some photos of cats\n",
    "query = \"cat\"\n",
    "crawler.goto(f\"https://www.pexels.com/search/{query}/\")\n",
    "\n",
    "\n",
    "grid = crawler.element_id(\"-\")\n",
    "images = crawler.children_of(grid, \"//article/a/img\", \"xpath\")\n",
    "\n",
    "# the first 10 results\n",
    "files = []\n",
    "for image in images[:6]:\n",
    "    img_url = image.get_attribute('src')\n",
    "    # get the filename from url using regex\n",
    "    result = re.findall(r\"./(.*?)\\?\", img_url)\n",
    "    img_filename = result[0].split('/')[-1]\n",
    "    files.append(img_filename)\n",
    "    ts.extractor.download(img_url, img_filename)\n",
    "crawler.quit()\n",
    "\n",
    "# just for you to check out the result:\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def make_html(file_name):\n",
    "    img_element = (\n",
    "         f'<img src=\"{file_name}\"'\n",
    "         + ' style=\"display:inline;margin:1px;width:100px;\"/>'\n",
    "    )\n",
    "    return img_element\n",
    "\n",
    "images = ''.join([make_html(file) for file in files])\n",
    "display(HTML(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click on buttons\n",
    "\n",
    "There are two methods of `Crawler` class for clicking buttons, or any other type of clickable elements:\n",
    "- `click_element`: receives an selenium webelement to click on.\n",
    "- `click`: receives value and attribute of element to be selected and clicked on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import thatscraper\n",
    "\n",
    "crawler = thatscraper.Crawler()\n",
    "\n",
    "url = \"https://unixpapa.com/js/testmouse.html\"\n",
    "crawler.goto(url)\n",
    "\n",
    "parent = crawler.element(\"//tbody/tr/td\", \"xpath\")\n",
    "# if you inspect the page, you'll see that any of the elements\n",
    "# are buttons, mas tow anchors and one image. Also,\n",
    "# there's a non clickable element: <br>. We can skip\n",
    "# it by making sure the element has 'onclick' function on it.\n",
    "buttons = crawler.children_of(parent, \".//*\", \"xpath\")\n",
    "for button in buttons:\n",
    "    if \"onclick\" in thatscraper.extractor.html(button):\n",
    "        crawler.click_element(button)\n",
    "        time.sleep(1)\n",
    "\n",
    "time.sleep(2)\n",
    "crawler.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.py39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "45f5eace5233fe4798a8204e9c7b50a33230de2c947354d5c069fec27b8fa1d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}